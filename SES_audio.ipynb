{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "from b2aiprep.dataset import VBAIDataset\n",
    "from b2aiprep.process import Audio, specgram, plot_spectrogram\n",
    "import IPython.display as Ipd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audiorecordings(from lectures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([476, 20])\n",
      "dict_keys(['speaker_embedding', 'specgram', 'melfilterbank', 'mfcc', 'sample_rate', 'opensmile'])\n"
     ]
    }
   ],
   "source": [
    "dataset = VBAIDataset('../bids_with_sensitive_recordings')\n",
    "data = torch.load('../bids_with_sensitive_recordings/sub-0e2df8b3-a93f-4982-a82c-d96a5c64d153/ses-461EA3E8-4477-4F97-B091-D21F4006B2FC/audio/sub-0e2df8b3-a93f-4982-a82c-d96a5c64d153_ses-461EA3E8-4477-4F97-B091-D21F4006B2FC_Audio-Check_rec-Audio-Check-1.pt')\n",
    "print(data[\"melfilterbank\"].shape)\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>record_id</th>\n",
       "      <th>demographics_session_id</th>\n",
       "      <th>demographics_duration</th>\n",
       "      <th>demographics_completed_by___1</th>\n",
       "      <th>demographics_completed_by___2</th>\n",
       "      <th>demographics_completed_by___3</th>\n",
       "      <th>state_province</th>\n",
       "      <th>country</th>\n",
       "      <th>gender_identity</th>\n",
       "      <th>...</th>\n",
       "      <th>household_count</th>\n",
       "      <th>spouse_partner_sig_other</th>\n",
       "      <th>children</th>\n",
       "      <th>parent</th>\n",
       "      <th>grandparent</th>\n",
       "      <th>other_live_with</th>\n",
       "      <th>others_household_specify</th>\n",
       "      <th>transportation_yn</th>\n",
       "      <th>primary_transportation</th>\n",
       "      <th>q_generic_demographics_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8d5dc52b-e8aa-42e7-ae54-8f05c4667d39</td>\n",
       "      <td>B176636C-3330-4AB4-93A9-1E2305506407</td>\n",
       "      <td>173.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>USA</td>\n",
       "      <td>Female gender identity</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Personal vehicle</td>\n",
       "      <td>Complete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             record_id  \\\n",
       "0           0  8d5dc52b-e8aa-42e7-ae54-8f05c4667d39   \n",
       "\n",
       "                demographics_session_id  demographics_duration  \\\n",
       "0  B176636C-3330-4AB4-93A9-1E2305506407                  173.0   \n",
       "\n",
       "   demographics_completed_by___1  demographics_completed_by___2  \\\n",
       "0                           True                          False   \n",
       "\n",
       "   demographics_completed_by___3 state_province country  \\\n",
       "0                          False      Tennessee     USA   \n",
       "\n",
       "          gender_identity  ... household_count spouse_partner_sig_other  \\\n",
       "0  Female gender identity  ...             4.0                       No   \n",
       "\n",
       "   children  parent  grandparent  other_live_with  others_household_specify  \\\n",
       "0       Yes     Yes           No               No                       NaN   \n",
       "\n",
       "   transportation_yn  primary_transportation  q_generic_demographics_complete  \n",
       "0                Yes        Personal vehicle                         Complete  \n",
       "\n",
       "[1 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg = pd.read_csv('../demographics.csv')\n",
    "dg.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>demographics_session_id</th>\n",
       "      <th>household_income_usa</th>\n",
       "      <th>household_income_ca</th>\n",
       "      <th>household_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8d5dc52b-e8aa-42e7-ae54-8f05c4667d39</td>\n",
       "      <td>B176636C-3330-4AB4-93A9-1E2305506407</td>\n",
       "      <td>$15,000 to $29,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1b07b18b-26f9-405b-a466-29442306a7fe</td>\n",
       "      <td>8F8E68BB-E68C-4EA5-B71A-17D7AAE915C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$150,000 to $199,999</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5db3e0c-6589-4a15-a5e7-8a95e4ed34a5</td>\n",
       "      <td>B94FE4BC-79FF-46A1-86CC-628E2D77874E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$50,000 to $99,999</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              record_id               demographics_session_id  \\\n",
       "0  8d5dc52b-e8aa-42e7-ae54-8f05c4667d39  B176636C-3330-4AB4-93A9-1E2305506407   \n",
       "1  1b07b18b-26f9-405b-a466-29442306a7fe  8F8E68BB-E68C-4EA5-B71A-17D7AAE915C2   \n",
       "2  e5db3e0c-6589-4a15-a5e7-8a95e4ed34a5  B94FE4BC-79FF-46A1-86CC-628E2D77874E   \n",
       "\n",
       "  household_income_usa   household_income_ca  household_count  \n",
       "0   $15,000 to $29,999                   NaN              4.0  \n",
       "1                  NaN  $150,000 to $199,999              4.0  \n",
       "2                  NaN    $50,000 to $99,999              1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = dg[[\"record_id\", \"demographics_session_id\"]]\n",
    "Y_income = dg [[\"household_income_usa\", \"household_income_ca\", \"household_count\"]]\n",
    "\n",
    "Train = dg[[\"record_id\", \"demographics_session_id\", \"household_income_usa\", \"household_income_ca\", \"household_count\"]]\n",
    "Train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before filtering:  (179, 5)\n",
      "Shape after filtering:  (115, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape before filtering: \",Train.shape)\n",
    "pre_train = Train[(pd.notna(Train['household_income_usa']) | pd.notna(Train['household_income_ca'])) &\n",
    "                                   (~((Train['household_income_usa'] == 'Prefer not to answer') | \n",
    "                                      (Train['household_income_ca'] == 'Prefer not to answer')))]\n",
    "print(\"Shape after filtering: \", pre_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SES\n",
      "2.0    37\n",
      "1.0    35\n",
      "3.0    29\n",
      "0.0    14\n",
      "Name: count, dtype: int64\n",
      "train SES\n",
      "2.0    33\n",
      "1.0    28\n",
      "3.0    23\n",
      "0.0     8\n",
      "Name: count, dtype: int64\n",
      "val  SES\n",
      "0.0    5\n",
      "1.0    3\n",
      "3.0    2\n",
      "2.0    1\n",
      "Name: count, dtype: int64\n",
      "test SES\n",
      "3.0    4\n",
      "1.0    4\n",
      "2.0    3\n",
      "0.0    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#label data: 0 - poverty, 1 - lower, 2 - middle, 3 - upper\n",
    "pre_train_labeled = pd.DataFrame(pre_train)\n",
    "\n",
    "for index, row in pre_train.iterrows():\n",
    "    if pd.notna(pre_train.loc[index, \"household_income_usa\"]) and pre_train.loc[index, \"household_count\"] >= 3: # USD; HH >= 3\n",
    "        income = pre_train.loc[index, \"household_income_usa\"]\n",
    "        if income in ['< $15,000', '$15,000 to $29,999']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 0\n",
    "        elif income in ['$30,000 to $$49,999']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 1\n",
    "        elif income in ['$50,000 to $99,999', '$100,000 to $149,999', '$150,000 to $199,999']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 2\n",
    "        elif income in ['$200,000 to $249,999', '>$250,000']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 3\n",
    "        elif income in ['Prefer not to answer']:\n",
    "            continue\n",
    "        else:\n",
    "            print(income)\n",
    "            raise ValueError(\"Wrong value for household_income_usa\")\n",
    "    \n",
    "    elif pd.notna(pre_train.loc[index, \"household_income_usa\"]): # USD; HH < 3\n",
    "        income = pre_train.loc[index, \"household_income_usa\"]\n",
    "        if income in ['< $15,000']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 0\n",
    "        elif income in ['$15,000 to $29,999', '$30,000 to $$49,999']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 1\n",
    "        elif income in ['$50,000 to $99,999']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 2\n",
    "        elif income in ['$100,000 to $149,999', '$150,000 to $199,999', '$200,000 to $249,999', '>$250,000']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 3\n",
    "        elif income in ['Prefer not to answer']:\n",
    "            continue\n",
    "        else:\n",
    "            print(income)\n",
    "            raise ValueError(\"Wrong value for household_income_usa\")\n",
    "        \n",
    "    elif pd.notna(pre_train.loc[index, \"household_income_ca\"]):  # CA; HH >= 3\n",
    "        income = pre_train.loc[index, \"household_income_ca\"]\n",
    "        if income in ['< $15,000', '$15,000 to $29,999']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 0\n",
    "        elif income in ['$30,000 to $$49,999']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 1\n",
    "        elif income in ['$50,000 to $99,999', '$100,000 to $149,999']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 2\n",
    "        elif income in ['$150,000 to $199,999', '$200,000 to $249,999', '>$250,000']:\n",
    "            pre_train_labeled.at[index, \"SES\"] = 3\n",
    "        elif income in ['Prefer not to answer']:\n",
    "            continue\n",
    "        else:\n",
    "            print(income)\n",
    "            raise ValueError(\"Wrong value for household_income_ca\")\n",
    "        \n",
    "    else:\n",
    "        print(index)\n",
    "        \n",
    "   \n",
    "one_hot = pd.get_dummies(pre_train_labeled['SES'], prefix='SES').astype(int)\n",
    "\n",
    "pre_train_labeled = pd.concat([pre_train_labeled, one_hot], axis=1)\n",
    "\n",
    "# display(\"Encoded labels: \", pre_train_labeled.head(3))\n",
    "# print(\"Shape: \", pre_train_labeled.shape)\n",
    "\n",
    "Y_label = pre_train_labeled.loc[:, \"SES\"]\n",
    "print(Y_label.value_counts())\n",
    "\n",
    "# Calculate the number of rows that correspond to the first 80%\n",
    "num_rows = int(len(pre_train_labeled) * 0.8)\n",
    "pre_train_labeled_first_80 = pre_train_labeled.iloc[:num_rows]\n",
    "\n",
    "# Extract the \"SES\" column\n",
    "Y_label_first_80 = pre_train_labeled_first_80.loc[:, \"SES\"]\n",
    "\n",
    "# Get the value counts for the \"SES\" column\n",
    "value_counts_first_80 = Y_label_first_80.value_counts()\n",
    "\n",
    "print(\"train\", value_counts_first_80)\n",
    "\n",
    "# Calculate the number of rows that correspond to the first 80%\n",
    "num_rows_2 = int(len(pre_train_labeled) * 0.1)\n",
    "pre_train_labeled_first_80 = pre_train_labeled.iloc[num_rows:(num_rows+num_rows_2)]\n",
    "\n",
    "# Extract the \"SES\" column\n",
    "Y_label_first_80 = pre_train_labeled_first_80.loc[:, \"SES\"]\n",
    "\n",
    "# Get the value counts for the \"SES\" column\n",
    "value_counts_first_80 = Y_label_first_80.value_counts()\n",
    "\n",
    "print(\"val \", value_counts_first_80)\n",
    "\n",
    "# Calculate the number of rows that correspond to the first 80%\n",
    "pre_train_labeled_first_80 = pre_train_labeled.iloc[(num_rows+num_rows_2):]\n",
    "\n",
    "# Extract the \"SES\" column\n",
    "Y_label_first_80 = pre_train_labeled_first_80.loc[:, \"SES\"]\n",
    "\n",
    "# Get the value counts for the \"SES\" column\n",
    "value_counts_first_80 = Y_label_first_80.value_counts()\n",
    "\n",
    "print(\"test\", value_counts_first_80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RainbowAudioDataset(torch.utils.data.Dataset):\n",
    "\tdef __init__(self, data):\n",
    "\t\t# self.segment_size = segment_size\n",
    "\t\tself.data = data\n",
    "\t\t\n",
    "\t\t# get location for every recording of rainbow passage\n",
    "\t\tfor index, row in data.iterrows():\n",
    "\t\t\tsubject = \"sub-\"+row['record_id']\n",
    "\t\t\tsession = \"ses-\"+row['demographics_session_id']\n",
    "\t\t\tlocation = str(\"../bids_with_sensitive_recordings/\" + subject + \"/\" + session + '/audio/'+subject+\"_\"+session+\"_Rainbow-Passage_rec-Rainbow-Passage.wav\")\n",
    "\t\t\tif os.path.exists(location):\n",
    "\t\t\t\tself.data.at[index, \"audio_location\"] = location\n",
    "\t\t\telse:\n",
    "\t\t\t\t# print all patients without Rainbow passage recording   \n",
    "\t\t\t\t# print(location)\n",
    "\t\t\t\t# data.at[index, \"audio_location\"] = None\n",
    "\t\t\t\tself.data = self.data.drop(index = index)\n",
    "\t\tself.data.reset_index(drop=True, inplace=True)\n",
    "\t\t# self.data = self.data.to_numpy()\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\taudio = Audio.from_file(self.data.loc[idx, \"audio_location\"])\n",
    "\t\taudio = audio.to_16khz().signal.squeeze()\n",
    "\t\td = (audio.size(0)-48000)//2\n",
    "\t\taudio = audio[d:d+48000]\n",
    "\t\t\n",
    "\t\tses = self.data.loc[idx, [\"SES_0.0\", \"SES_1.0\", \"SES_2.0\", \"SES_3.0\"]].to_numpy(dtype=np.float32)\n",
    "\t\tses = torch.tensor(ses, dtype=torch.float32)\n",
    "\t\t\n",
    "\t\treturn {'signal': audio, 'SES': ses}\n",
    "\n",
    "\t\t# # get middle K seconds if audio is too long, pad with zeros if it is too short\n",
    "\t\t# if audio.size(0) > self.segment_size*16000:\n",
    "\t\t# \td = (audio.size(0)-self.segment_size*16000)//2\n",
    "\t\t# \taudio = audio[d:d+self.segment_size*16000]\n",
    "\t\t# else:\n",
    "\t\t# \taudio = torch.nn.functional.pad(audio, (0,self.segment_size*16000-audio.size(0)), mode='constant', value=0)\n",
    "\n",
    "\tdef analyze_length(self):\n",
    "\t\ttotal_length = 0\n",
    "\t\tmin_val = 10e9\n",
    "\t\tmax_val = 0\n",
    "\t\tfor idx in range(len(self.data)):\n",
    "\t\t\taudio = Audio.from_file(self.data.loc[idx, \"audio_location\"])\n",
    "\t\t\taudio = audio.to_16khz().signal.squeeze()\n",
    "\t\t\tlength = audio.size(0)  # Number of samples in the audio\n",
    "\t\t\tmin_val = min_val if min_val < length else length\n",
    "\t\t\tmax_val = max_val if max_val > length else length\n",
    "\t\t\ttotal_length += length\n",
    "\t\taverage_length = total_length / len(self.data)\n",
    "\t\treturn average_length, min_val, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>demographics_session_id</th>\n",
       "      <th>household_income_usa</th>\n",
       "      <th>household_income_ca</th>\n",
       "      <th>household_count</th>\n",
       "      <th>SES</th>\n",
       "      <th>SES_0.0</th>\n",
       "      <th>SES_1.0</th>\n",
       "      <th>SES_2.0</th>\n",
       "      <th>SES_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8d5dc52b-e8aa-42e7-ae54-8f05c4667d39</td>\n",
       "      <td>B176636C-3330-4AB4-93A9-1E2305506407</td>\n",
       "      <td>$15,000 to $29,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1b07b18b-26f9-405b-a466-29442306a7fe</td>\n",
       "      <td>8F8E68BB-E68C-4EA5-B71A-17D7AAE915C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$150,000 to $199,999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5db3e0c-6589-4a15-a5e7-8a95e4ed34a5</td>\n",
       "      <td>B94FE4BC-79FF-46A1-86CC-628E2D77874E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$50,000 to $99,999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>943a8bbc-bba0-4853-825c-10cae1b26ddd</td>\n",
       "      <td>35002E1F-A963-4E9C-8F2A-738839D83C4D</td>\n",
       "      <td>$15,000 to $29,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d5aeba9f-c910-4b65-81e8-0e9ad15097e7</td>\n",
       "      <td>8B341FFA-28B5-46B8-97D1-2B68F5882185</td>\n",
       "      <td>$50,000 to $99,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2de86669-cc1f-45ef-9d31-a7eabd68f247</td>\n",
       "      <td>07E782FE-DF6F-4CFF-BA9A-1A394845E0B3</td>\n",
       "      <td>$150,000 to $199,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>92425dec-8998-43bf-adfc-00414c66b9a2</td>\n",
       "      <td>BD5B8396-2ACB-4FA9-97CE-4498C46023D6</td>\n",
       "      <td>&gt;$250,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>28cc3eda-66eb-4731-b5fa-e59f2cbaf801</td>\n",
       "      <td>744EA686-2B23-4770-980B-96D4D2962D85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$50,000 to $99,999</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>dbd7641f-f3db-4d08-8f63-2e0e7bbb8f3d</td>\n",
       "      <td>7DCE811B-CDAE-4DAB-B2B6-EDE0BF9534D4</td>\n",
       "      <td>$150,000 to $199,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>ba749edd-38d9-4f87-8742-c71010177050</td>\n",
       "      <td>EB224313-6A0F-496D-803B-41CFD3AF420A</td>\n",
       "      <td>$50,000 to $99,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                record_id  \\\n",
       "0    8d5dc52b-e8aa-42e7-ae54-8f05c4667d39   \n",
       "1    1b07b18b-26f9-405b-a466-29442306a7fe   \n",
       "2    e5db3e0c-6589-4a15-a5e7-8a95e4ed34a5   \n",
       "3    943a8bbc-bba0-4853-825c-10cae1b26ddd   \n",
       "4    d5aeba9f-c910-4b65-81e8-0e9ad15097e7   \n",
       "..                                    ...   \n",
       "170  2de86669-cc1f-45ef-9d31-a7eabd68f247   \n",
       "171  92425dec-8998-43bf-adfc-00414c66b9a2   \n",
       "172  28cc3eda-66eb-4731-b5fa-e59f2cbaf801   \n",
       "176  dbd7641f-f3db-4d08-8f63-2e0e7bbb8f3d   \n",
       "178  ba749edd-38d9-4f87-8742-c71010177050   \n",
       "\n",
       "                  demographics_session_id  household_income_usa  \\\n",
       "0    B176636C-3330-4AB4-93A9-1E2305506407    $15,000 to $29,999   \n",
       "1    8F8E68BB-E68C-4EA5-B71A-17D7AAE915C2                   NaN   \n",
       "2    B94FE4BC-79FF-46A1-86CC-628E2D77874E                   NaN   \n",
       "3    35002E1F-A963-4E9C-8F2A-738839D83C4D    $15,000 to $29,999   \n",
       "4    8B341FFA-28B5-46B8-97D1-2B68F5882185    $50,000 to $99,999   \n",
       "..                                    ...                   ...   \n",
       "170  07E782FE-DF6F-4CFF-BA9A-1A394845E0B3  $150,000 to $199,999   \n",
       "171  BD5B8396-2ACB-4FA9-97CE-4498C46023D6             >$250,000   \n",
       "172  744EA686-2B23-4770-980B-96D4D2962D85                   NaN   \n",
       "176  7DCE811B-CDAE-4DAB-B2B6-EDE0BF9534D4  $150,000 to $199,999   \n",
       "178  EB224313-6A0F-496D-803B-41CFD3AF420A    $50,000 to $99,999   \n",
       "\n",
       "      household_income_ca  household_count  SES  SES_0.0  SES_1.0  SES_2.0  \\\n",
       "0                     NaN              4.0  0.0        1        0        0   \n",
       "1    $150,000 to $199,999              4.0  3.0        0        0        0   \n",
       "2      $50,000 to $99,999              1.0  2.0        0        0        1   \n",
       "3                     NaN              1.0  1.0        0        1        0   \n",
       "4                     NaN              2.0  2.0        0        0        1   \n",
       "..                    ...              ...  ...      ...      ...      ...   \n",
       "170                   NaN              2.0  3.0        0        0        0   \n",
       "171                   NaN              2.0  3.0        0        0        0   \n",
       "172    $50,000 to $99,999              2.0  2.0        0        0        1   \n",
       "176                   NaN              2.0  3.0        0        0        0   \n",
       "178                   NaN              2.0  2.0        0        0        1   \n",
       "\n",
       "     SES_3.0  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "170        1  \n",
       "171        1  \n",
       "172        0  \n",
       "176        1  \n",
       "178        0  \n",
       "\n",
       "[115 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464351.10714285716 282947 808798\n"
     ]
    }
   ],
   "source": [
    "display(pre_train_labeled)\n",
    "dataset = RainbowAudioDataset(pre_train_labeled)\n",
    "avg, min_val, max_val = dataset.analyze_length()\n",
    "print(avg, min_val, max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SES  SES_0.0  SES_1.0  SES_2.0  SES_3.0\n",
      "2.0  0        0        1        0          30\n",
      "1.0  0        1        0        0          28\n",
      "3.0  0        0        0        1          23\n",
      "0.0  1        0        0        0          11\n",
      "Name: count, dtype: int64\n",
      "SES  SES_0.0  SES_1.0  SES_2.0  SES_3.0\n",
      "1.0  0        1        0        0          3\n",
      "2.0  0        0        1        0          3\n",
      "3.0  0        0        0        1          3\n",
      "0.0  1        0        0        0          2\n",
      "Name: count, dtype: int64\n",
      "SES  SES_0.0  SES_1.0  SES_2.0  SES_3.0\n",
      "1.0  0        1        0        0          4\n",
      "2.0  0        0        1        0          4\n",
      "3.0  0        0        0        1          3\n",
      "0.0  1        0        0        0          1\n",
      "Name: count, dtype: int64\n",
      "torch.Size([16, 48000])\n",
      "torch.Size([16, 4])\n"
     ]
    }
   ],
   "source": [
    "X = pre_train_labeled[['record_id', 'demographics_session_id']]\n",
    "y = pre_train_labeled[['SES', 'SES_0.0', 'SES_1.0', 'SES_2.0', 'SES_3.0']]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_val.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "val_df = pd.concat([X_val, y_val], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "N = len(pre_train_labeled)\n",
    "\n",
    "train_dataset = RainbowAudioDataset(pre_train_labeled[:int(0.8*N)])\n",
    "val_dataset = RainbowAudioDataset(pre_train_labeled[int(0.8*N):int(0.9*N)])\n",
    "test_dataset = RainbowAudioDataset(pre_train_labeled[int(0.9*N):])\n",
    "\n",
    "# train_dataset = RainbowAudioDataset(train_df)\n",
    "# val_dataset = RainbowAudioDataset(val_df)\n",
    "# test_dataset = RainbowAudioDataset(test_df)\n",
    "\n",
    "# print(train_dataset[1])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    print(batch['signal'].shape)\n",
    "    print(batch['SES'].shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=11, stride=32, padding=0)\n",
    "        self.mp = nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "  \n",
    "        # Calculate the input size to the linear layer\n",
    "        self.fc_input_size = self._calculate_fc_input_size()\n",
    "  \n",
    "        self.fc = torch.nn.Linear(self.fc_input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mp(torch.nn.functional.relu(self.conv1(x)))\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.dropout(x)  # Apply dropout before the linear layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def _calculate_fc_input_size(self):\n",
    "        # Example calculation assuming input size (1, 48000)\n",
    "        x = torch.randn(1, 1, 48000)\n",
    "        x = self.mp(nn.functional.relu(self.conv1(x)))\n",
    "        return x.view(x.size(0), -1).size(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 1500]             768\n",
      "         MaxPool1d-2              [-1, 64, 500]               0\n",
      "           Dropout-3                [-1, 32000]               0\n",
      "            Linear-4                    [-1, 4]         128,004\n",
      "================================================================\n",
      "Total params: 128,772\n",
      "Trainable params: 128,772\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.18\n",
      "Forward/backward pass size (MB): 1.22\n",
      "Params size (MB): 0.49\n",
      "Estimated Total Size (MB): 1.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# cnn = CNN_1D(4)\n",
    "cnn = CNN_1D(num_classes=4)\n",
    "_ = summary(cnn, (1, 48000))\n",
    "# for batch in train_dataloader:\n",
    "#     out = cnn(batch['signal'].unsqueeze(1)).squeeze(1)[0]\n",
    "#     out = torch.tensor([0.1, 0.2, 1, 10])\n",
    "#     print(out)\n",
    "#     print(torch.nn.functional.softmax(out))\n",
    "#     print()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 11.291212971290845, Val Acc: 0.09090909090909091\n",
      "Epoch 2/20, Loss: 7.2851874426509555, Val Acc: 0.18181818181818182\n",
      "Epoch 3/20, Loss: 3.54530735230178, Val Acc: 0.36363636363636365\n",
      "Epoch 4/20, Loss: 1.684962461503704, Val Acc: 0.2727272727272727\n",
      "Epoch 5/20, Loss: 0.9966382169991397, Val Acc: 0.2727272727272727\n",
      "Epoch 6/20, Loss: 0.7092560924840777, Val Acc: 0.18181818181818182\n",
      "Epoch 7/20, Loss: 0.63192523396417, Val Acc: 0.18181818181818182\n",
      "Epoch 8/20, Loss: 0.4663518908318509, Val Acc: 0.18181818181818182\n",
      "Epoch 9/20, Loss: 0.37390894802768576, Val Acc: 0.18181818181818182\n",
      "Epoch 10/20, Loss: 0.3117556138319916, Val Acc: 0.18181818181818182\n",
      "Epoch 11/20, Loss: 0.25304443916577973, Val Acc: 0.18181818181818182\n",
      "Epoch 12/20, Loss: 0.23693065462487467, Val Acc: 0.18181818181818182\n",
      "Epoch 13/20, Loss: 0.2224369916353333, Val Acc: 0.18181818181818182\n",
      "Epoch 14/20, Loss: 0.21841906563619548, Val Acc: 0.18181818181818182\n",
      "Epoch 15/20, Loss: 0.20201160197847345, Val Acc: 0.18181818181818182\n",
      "Epoch 16/20, Loss: 0.2040495343422622, Val Acc: 0.18181818181818182\n",
      "Epoch 17/20, Loss: 0.1878819041205256, Val Acc: 0.18181818181818182\n",
      "Epoch 18/20, Loss: 0.17773708550447828, Val Acc: 0.18181818181818182\n",
      "Epoch 19/20, Loss: 0.16164464545383883, Val Acc: 0.18181818181818182\n",
      "Epoch 20/20, Loss: 0.16199590048093473, Val Acc: 0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "def eval(model, dataloader, verbose = False):\n",
    "\tmodel.eval()\n",
    "\tacc = 0\n",
    "\ttotal = 0\n",
    "\tfor batch in dataloader:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutputs = torch.nn.functional.softmax(model(batch['signal'].unsqueeze(1)).squeeze(1))\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(outputs)\n",
    "\t\tfor i in range(len(batch['signal'])):\n",
    "\t\t\t_, predicted = torch.max(outputs, 1)\n",
    "\t\t\t_, ground_truth = torch.max(batch['SES'], 1)\n",
    "\t\t\tacc += (predicted == ground_truth).sum().item()\n",
    "\t\t\ttotal += ground_truth.size(0)\n",
    "\t\t\t# _, predicted = torch.max(outputs, 1)\n",
    "\t\t\t# _, ground_truth = torch.max(batch['SES'], 1)\n",
    "\t\t\t# acc += (predicted == ground_truth).sum().item()\n",
    "\tif verbose:\n",
    "\t\treturn acc/total, outputs\n",
    "\treturn acc/total\t\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    cnn.train()\n",
    "    closs = []\n",
    "    for batch in train_dataloader:        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(batch['signal'].unsqueeze(1))\n",
    "        loss = criterion(outputs, batch['SES'].argmax(dim=1))\n",
    "        closs += [loss.item()] * len(batch['signal'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    val_acc = eval(cnn, val_dataloader)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(cnn.state_dict(), 'mymodel.pth')\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {sum(closs)/len(closs)}, Val Acc: {val_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.1345e-01, 1.1921e-03, 4.7476e-01, 1.1060e-01],\n",
      "        [5.1693e-01, 9.9078e-04, 4.2057e-01, 6.1507e-02],\n",
      "        [4.1406e-01, 1.8970e-04, 4.1604e-01, 1.6971e-01],\n",
      "        [3.1798e-01, 9.1318e-04, 6.0316e-01, 7.7950e-02],\n",
      "        [3.3482e-01, 9.1574e-04, 5.9679e-01, 6.7476e-02],\n",
      "        [3.4803e-01, 8.2322e-04, 5.0423e-01, 1.4692e-01],\n",
      "        [3.3179e-01, 9.4600e-04, 5.9848e-01, 6.8787e-02],\n",
      "        [3.4281e-01, 8.9685e-04, 5.8859e-01, 6.7711e-02],\n",
      "        [3.4344e-01, 9.3260e-04, 5.8647e-01, 6.9160e-02],\n",
      "        [3.2558e-01, 8.2354e-04, 6.0175e-01, 7.1856e-02],\n",
      "        [5.6935e-01, 9.8688e-04, 2.6370e-01, 1.6597e-01],\n",
      "        [3.3380e-01, 9.4796e-04, 5.9742e-01, 6.7834e-02]])\n",
      "tensor([2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2])\n",
      "       [1. 2. 3. 1. 2. 1. 2. 3. 2. 0. 3. 1.]\n",
      "TestACC:0.2500\n"
     ]
    }
   ],
   "source": [
    "cnn.load_state_dict(torch.load('./mymodel.pth'))\n",
    "test_acc, outputs = eval(cnn, test_dataloader, verbose=True)\n",
    "print(outputs.argmax(dim=1))\n",
    "print(\"      \", y_test.loc[:, \"SES\"].to_numpy())\n",
    "print('TestACC:{:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CNN_1D' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Just for plotting\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m(test_features, test_labels)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\artkr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CNN_1D' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "# Just for plotting\n",
    "\n",
    "test_loss, test_accuracy = cnn.evaluate(test_features, test_labels)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "test_predictions = (cnn.predict(test_features) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Not Race_5', 'Race_5'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
